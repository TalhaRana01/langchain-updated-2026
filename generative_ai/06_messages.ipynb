{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ea51c3",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "- Role : Identifies the message type (e.g system, user)\n",
    "- Content : Represents the actual content of the message (like, text, images, audio, documents, etc)\n",
    "- Metadata : Optional fields such as response information,  message IDs, and token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07fc20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c850041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked me about AI, so I need to provide a comprehensive overview. First, I should start by defining AI and its main branches like machine learning and deep learning. Then mention common applications such as image recognition, natural language processing, and autonomous vehicles. It\\'s important to note the different types of AI, like narrow AI versus general AI, and maybe touch on ethical issues like bias and privacy. I should also include current trends and future directions. But wait, the user might be new to AI, so I should explain technical terms in simple language. Let me check if I covered all the key points without getting too technical. Maybe start with a brief history of AI, then move into key concepts and applications. Also, mention how AI is used in everyday technologies like voice assistants and recommendation systems. Don\\'t forget the challenges AI faces, such as data requirements and computational costs. Oh, and ethical considerations are crucial nowadays, so that\\'s a must-include. Let me organize this into sections for clarity. Alright, I think that\\'s a solid outline. Now, time to put it all together in a clear and concise manner.\\n</think>\\n\\nArtificial Intelligence (AI) is a branch of computer science focused on creating systems that can perform tasks requiring human-like intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. Here\\'s a structured overview of AI:\\n\\n### **Key Concepts in AI**\\n1. **Machine Learning (ML):**  \\n   A subset of AI where algorithms learn patterns from data without explicit programming. Common techniques include:\\n   - **Supervised Learning**: Uses labeled data (e.g., predicting house prices based on features like size).\\n   - **Unsupervised Learning**: Finds hidden patterns in unlabeled data (e.g., clustering customer segments).\\n   - **Reinforcement Learning**: Learns by trial-and-error with rewards/penalties (e.g., training autonomous vehicles).\\n\\n2. **Deep Learning:**  \\n   A specialized form of ML using neural networks with multiple layers to model complex patterns. It excels in tasks like image and speech recognition.\\n\\n3. **Natural Language Processing (NLP):**  \\n   Enables machines to understand and generate human language. Applications include chatbots, translation tools, and sentiment analysis.\\n\\n4. **Computer Vision:**  \\n   Focuses on interpreting visual data (images/ videos). Used in facial recognition, medical imaging, and surveillance.\\n\\n---\\n\\n### **Types of AI**\\n- **Narrow AI (Weak AI):**  \\n  Specialized in specific tasks (e.g., GPS navigation, voice assistants like Siri or Alexa). Most current systems fall into this category.\\n  \\n- **General AI (Strong AI):**  \\n  Hypothetical AI that can perform *any* intellectual task a human can. It does not yet exist and remains a long-term research goal.\\n\\n---\\n\\n### **Applications of AI**\\n- **Healthcare:** Diagnosing diseases, drug discovery, and personalized treatment plans.\\n- **Finance:** Fraud detection, algorithmic trading, and credit risk assessment.\\n- **Transportation:** Autonomous vehicles and traffic optimization.\\n- **Retail:** Personalized recommendations and inventory management.\\n- **Manufacturing:** Predictive maintenance and quality control.\\n- **Customer Service:** Chatbots and virtual assistants.\\n\\n---\\n\\n### **Challenges and Ethical Considerations**\\n1. **Bias and Fairness:**  \\n   AI systems can inherit biases from training data, leading to unfair outcomes (e.g., discriminatory hiring tools). Mitigation involves diverse datasets and fairness-aware algorithms.\\n\\n2. **Privacy:**  \\n   Data collection for AI raises concerns about user privacy. Techniques like federated learning (training on decentralized data) aim to address this.\\n\\n3. **Transparency:**  \\n   Many AI models (e.g., deep learning) are \"black boxes,\" making their decision-making opaque. Explainable AI (XAI) seeks to make models interpretable.\\n\\n4. **Job Displacement:**  \\n   Automation may replace certain jobs, though it also creates new roles in AI development and oversight.\\n\\n5. **Security Risks:**  \\n   AI can be exploited for deepfakes, autonomous weapons, or adversarial attacks (e.g., tricking systems with manipulated inputs).\\n\\n---\\n\\n### **Current Trends and Future Directions**\\n- **AI Democratization:** Tools like Google‚Äôs TensorFlow and Hugging Face‚Äôs NLP libraries make AI accessible to non-experts.\\n- **AI for Good:** Applications in climate modeling, disaster response, and poverty alleviation.\\n- **AI Ethics and Regulation:** Governments are introducing frameworks (e.g., the EU‚Äôs AI Act) to govern AI development responsibly.\\n- **Hybrid AI:** Combining human expertise with AI, such as in collaborative robotics (cobots) or AI-assisted medical diagnosis.\\n\\n---\\n\\n### **Notable AI Milestones**\\n- **1997:** IBM‚Äôs Deep Blue defeats Garry Kasparov in chess.\\n- **2011:** IBM Watson wins *Jeopardy!* against human champions.\\n- **2016:** AlphaGo (DeepMind) beats world champion Lee Sedol in Go.\\n- **2023:** Large Language Models (LLMs) like GPT-4 and Gemini achieve human-like text generation and reasoning.\\n\\n---\\n\\n### **How AI Impacts Daily Life**\\n- **Smart Devices:** Voice assistants, smart home systems, and recommendation algorithms (Netflix, Spotify).\\n- **Healthcare:** AI-driven diagnostics and wearable health monitors.\\n- **Social Media:** Content recommendation, moderation, and trend analysis.\\n\\n---\\n\\nAI is transformative but requires careful management to maximize benefits while minimizing risks. If you\\'d like to dive deeper into a specific area (e.g., ethics, technical details, or applications), feel free to ask! ü§ñ', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1168, 'prompt_tokens': 14, 'total_tokens': 1182, 'completion_time': 2.357050553, 'completion_tokens_details': None, 'prompt_time': 0.000686674, 'prompt_tokens_details': None, 'queue_time': 0.264585417, 'total_time': 2.357737227}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_efa9879028', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb733-7dfb-7552-aaf8-50d2492e88ef-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 1168, 'total_tokens': 1182})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Please tell me something about AI\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48da541",
   "metadata": {},
   "source": [
    "### Text Prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you don't need to retain conversation history.\n",
    "\n",
    "Use Text prompts when:\n",
    "  - You have a single , standalone request\n",
    "  - You don't need conversation history\n",
    "  - You want minimal code complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720eb5a1",
   "metadata": {},
   "source": [
    "### Messages Prompts \n",
    "\n",
    "Alternatively, you can pass in a **list of messages to the model** by providing a list of message objects.\n",
    "\n",
    "**Messages Types**\n",
    "\n",
    "1. **System Message** - Tell the model how to behave and provide conect for interactions\n",
    "2. **Human Message** - Represent user input and interactions with the model.\n",
    "3. **AI Message** - Responses genereated by the model, including text content, tool calls, and metadata.\n",
    "4. **Tool Message** - Represents the outputs of the tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf418a",
   "metadata": {},
   "source": [
    "**System Message**\n",
    "```\n",
    " A SystemMessage represent an initial set of instructions that primes the model's bahavior. You can use a sysyem message to set the tone, define the model's role, and establish guidelines for a responses.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218995a",
   "metadata": {},
   "source": [
    "**Human Message**\n",
    "\n",
    "```\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodel content\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c36d2",
   "metadata": {},
   "source": [
    "**AI Message**\n",
    "\n",
    "```\n",
    "An AIMessage represents the output of a model invocation.They can include multimodel data, tool calls, and provider-specific metadata that you can later access\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa7fa310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user is asking for the capital of France. Let me think. I know that France is a country in Europe. The capital... Hmm, I remember that the capital is Paris. Wait, is that correct? I think so. Let me double-check. Yeah, Paris is definitely the capital city of France. It's a major city, known for landmarks like the Eiffel Tower and the Louvre. I don't think there's any other city that's the capital. Maybe they're confused with another French-speaking country, like Belgium or Switzerland, but France's capital is definitely Paris. So the answer should be Paris.\\n</think>\\n\\nThe capital of France is **Paris**. It is a major cultural and historical city, known for its landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 34, 'total_tokens': 209, 'completion_time': 0.362544303, 'completion_tokens_details': None, 'prompt_time': 0.001503896, 'prompt_tokens_details': None, 'queue_time': 0.024185817, 'total_time': 0.364048199}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb854-9ccd-7900-a203-006a0b79fd96-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 34, 'output_tokens': 175, 'total_tokens': 209})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "  SystemMessage(content=\"You are a helpful assistant that can answer questions and help with tasks.\"),\n",
    "  HumanMessage(content=\"What is the capital of France?\"),\n",
    "  \n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfe225f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants to create a REST API. Let me think about the best way to approach this. They might be new to REST or Python, so I should start with the basics.\n",
      "\n",
      "First, choosing a framework is essential. Flask and Django are popular in Python. Flask is lightweight and good for learning, while Django has more built-in features. Since the question is about creating a REST API, maybe Flask with Flask-RESTful would be a good fit because it's straightforward for APIs.\n",
      "\n",
      "I should outline the steps: install the necessary packages, set up the app, define resources, and run the server. Let me make sure to mention the installation commands like pip install flask flask-restful. Then, create a simple example with a resource that handles GET and POST requests.\n",
      "\n",
      "Wait, maybe I should explain what each part does. For example, the Resource class in Flask-RESTful handles different HTTP methods. Also, the add_resource function maps the endpoint to the resource. Including an example with JSON data would help, like returning a list of items.\n",
      "\n",
      "But what about data persistence? Maybe the user wants to store data. I can mention using an in-memory list for simplicity, but note that in production, a database would be better. That way, they know to look into databases next if they need it.\n",
      "\n",
      "Testing the API with curl or Postman could be useful. Provide example commands so they can test their endpoints. Also, running the app with app.run(debug=True) is helpful during development but should be changed for production.\n",
      "\n",
      "I should also mention best practices, like using proper HTTP status codes and error handling. Maybe point out that this is a basic example and real-world APIs need more features like authentication, rate limiting, etc.\n",
      "\n",
      "Is there anything else? Oh, maybe a note about URL structure and how to add more endpoints. Also, the importance of using POST for creating resources and GET for retrieving. Make sure the example covers these methods.\n",
      "\n",
      "Let me put it all together in a step-by-step guide with code examples. Keep the code clean and explain each part. That should cover the essentials for someone starting out with REST APIs in Python.\n",
      "</think>\n",
      "\n",
      "To create a REST API in Python, use **Flask** with **Flask-RESTful** for simplicity. Here's a step-by-step guide:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Install Dependencies**\n",
      "```bash\n",
      "pip install flask flask-restful\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Basic REST API Example**\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request\n",
      "from flask_restful import Api, Resource\n",
      "\n",
      "app = Flask(__name__)\n",
      "api = Api(app)\n",
      "\n",
      "# In-memory data store (replace with a database in production)\n",
      "items = []\n",
      "\n",
      "# Resource for managing items\n",
      "class ItemResource(Resource):\n",
      "    def get(self, item_id):\n",
      "        for item in items:\n",
      "            if item['id'] == item_id:\n",
      "                return item, 200\n",
      "        return {'message': 'Item not found'}, 404\n",
      "\n",
      "    def post(self):\n",
      "        data = request.get_json()\n",
      "        item = {\n",
      "            'id': len(items) + 1,\n",
      "            'name': data['name'],\n",
      "            'description': data.get('description', '')\n",
      "        }\n",
      "        items.append(item)\n",
      "        return item, 201\n",
      "\n",
      "    def put(self, item_id):\n",
      "        data = request.get_json()\n",
      "        for item in items:\n",
      "            if item['id'] == item_id:\n",
      "                item['name'] = data.get('name', item['name'])\n",
      "                item['description'] = data.get('description', item['description'])\n",
      "                return item, 200\n",
      "        return {'message': 'Item not found'}, 404\n",
      "\n",
      "    def delete(self, item_id):\n",
      "        global items\n",
      "        items = [item for item in items if item['id'] != item_id]\n",
      "        return {'message': 'Item deleted'}, 200\n",
      "\n",
      "# Add endpoints\n",
      "api.add_resource(ItemResource, '/items', '/items/<int:item_id>')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Key Concepts Explained**\n",
      "\n",
      "- **Flask**: The web framework for routing and handling requests.\n",
      "- **Flask-RESTful**: Simplifies creating RESTful endpoints with `Resource` classes.\n",
      "- **HTTP Methods**:\n",
      "  - `GET /items/<id>`: Retrieve a specific item.\n",
      "  - `POST /items`: Create a new item.\n",
      "  - `PUT /items/<id>`: Update an existing item.\n",
      "  - `DELETE /items/<id>`: Delete an item.\n",
      "- **Data Handling**: Uses an in-memory list (`items`) for simplicity. Replace with a database (e.g., SQLAlchemy, MongoDB) for production.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Test the API**\n",
      "\n",
      "Use `curl` or Postman:\n",
      "\n",
      "#### Create an Item\n",
      "```bash\n",
      "curl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"Laptop\", \"description\": \"High-end\"}' http://127.0.0.1:5000/items\n",
      "```\n",
      "\n",
      "#### Get an Item\n",
      "```bash\n",
      "curl http://127.0.0.1:5000/items/1\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **Next Steps for Production**\n",
      "- Add authentication (e.g., JWT).\n",
      "- Use a database (e.g., PostgreSQL with SQLAlchemy).\n",
      "- Add validation and error handling.\n",
      "- Use environment variables for configuration.\n",
      "- Deploy with a production server (e.g., Gunicorn + Nginx).\n",
      "\n",
      "---\n",
      "\n",
      "This example provides a foundation. Expand it with features like pagination, filtering, and rate limiting as needed.\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "# print(response.usage_metadata)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e45eb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked \"What\\'s 2+2?\" after I said I can help. Hmm, 2+2 is a basic math question. Let me make sure I get this right. In standard arithmetic, 2 plus 2 is 4. But wait, are there any contexts where it might not be 4? Like in different number bases or something? For example, in base 3, 2+2 would be 11, but the user probably expects the base 10 answer. Also, sometimes people use 2+2 as a metaphor or joke, but in a straightforward math question, it\\'s safe to assume they want the numerical answer. The user seems to be testing my basic math skills here. I should confirm the answer is 4 and maybe add a friendly note to show I\\'m paying attention. Let me check if there\\'s any trick to the question. Nope, looks straightforward. So the answer is 4. I should respond clearly and confidently.\\n</think>\\n\\n2 + 2 equals **4**! üòä Let me know if you have any trickier questions‚ÄîI‚Äôm here for those too.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 237, 'prompt_tokens': 53, 'total_tokens': 290, 'completion_time': 0.546836837, 'completion_tokens_details': None, 'prompt_time': 0.002381432, 'prompt_tokens_details': None, 'queue_time': 0.025103595, 'total_time': 0.549218269}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb858-d488-72e1-be2c-8e68d947d985-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 53, 'output_tokens': 237, 'total_tokens': 290})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc4ea085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "Args: {'location': 'Paris'}\n",
      "ID: sc3wn0641\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    ...\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "response = model_with_tools.invoke(\"What's the weather in Paris?\")\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")\n",
    "    print(f\"ID: {tool_call['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb706a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked for the weather in San Francisco. I called the get_weather function with the location parameter set to \"San Francisco\". The response came back as \"Sunny, 72¬∞F\". Now I need to present this information in a clear and friendly way. Let me check if there\\'s any additional details I should mention. The user might want to know about the chance of rain, wind speed, or humidity, but the function only provided temperature and condition. I should stick to the given data. Make sure to mention the location again to confirm it\\'s the correct city. Maybe add an emoji for the weather to make it more visual. Alright, putting it all together: \"The current weather in San Francisco is sunny with a temperature of 72¬∞F. ‚òÄÔ∏è Enjoy the pleasant day!\" That sounds good. Double-check for any errors. All set.\\n</think>\\n\\nThe current weather in San Francisco is sunny with a temperature of 72¬∞F. ‚òÄÔ∏è Enjoy the pleasant day!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 208, 'prompt_tokens': 57, 'total_tokens': 265, 'completion_time': 0.460175578, 'completion_tokens_details': None, 'prompt_time': 0.002709327, 'prompt_tokens_details': None, 'queue_time': 0.007106355, 'total_time': 0.462884905}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb860-b4ee-7423-84ff-a954588c3a2e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 57, 'output_tokens': 208, 'total_tokens': 265})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72¬∞F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
