{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad801f",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2fc79",
   "metadata": {},
   "source": [
    "**Models** can request to call tools that perform tasks such as fetching data from a database, searching the web, or running code.\n",
    "**Tools** are pairing of:\n",
    "\n",
    "1. A Schema including the name of the tool, a description, and/or argument definations(often a JSON schema).\n",
    "2. A function or coroutine to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518ca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f1aa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT MODEL\n",
    "# model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "# GROQ MODEL\n",
    "model = init_chat_model(\"groq:llama-3.3-70b-versatile\")\n",
    "\n",
    "# GOOGLE MODEL\n",
    "# model = init_chat_model(model=\"google_genai:gemini-flash-latest\")\n",
    "\n",
    "# response = model.stream(\"How airplanes fly?\")\n",
    "\n",
    "# for chunk in response:\n",
    "#   print(chunk.text, end=\" \", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "179f96c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'zpq127qty', 'function': {'arguments': '{\"location\":\"Berani Sindh Pakistan\"}', 'name': 'get_weather'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 225, 'total_tokens': 243, 'completion_time': 0.05762879, 'completion_tokens_details': None, 'prompt_time': 0.013792215, 'prompt_tokens_details': None, 'queue_time': 0.008636809, 'total_time': 0.071421005}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bb1e4-8390-7ab3-b556-689d63bcfb7a-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Berani Sindh Pakistan'}, 'id': 'zpq127qty', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 225, 'output_tokens': 18, 'total_tokens': 243}\n",
      "[{'name': 'get_weather', 'args': {'location': 'Berani Sindh Pakistan'}, 'id': 'zpq127qty', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Tools - Define karna\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "  \"\"\"Get the weather in a given location\"\"\"\n",
    "  return f\"The weather in {location} is sunny\"\n",
    "\n",
    "# Tool ko model ke saath bind karna\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(\"What is the weather in Berani Sindh Pakistan?\")\n",
    "print(response)\n",
    "\n",
    "tools_calling = response.tool_calls\n",
    "print(tools_calling)\n",
    "\n",
    "# if tools_calling:\n",
    "#   tool_call = tools_calling[0]\n",
    "#   print(f\"\\nTool Name: {tool_call['name']}\")\n",
    "#   print(f\"Arguments: {tool_call['args']}\")\n",
    "#   print(f\"Tool Call ID: {tool_call['id']}\")\n",
    "  \n",
    "  \n",
    "#   # Actual tool ko execute karna\n",
    "#   location = tool_call['args']['location']\n",
    "#   result = get_weather.invoke({\"location\": location})\n",
    "#   print(f\"\\nTool Result: {result}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bbab34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Berani Sindh is sunny.\n"
     ]
    }
   ],
   "source": [
    "## Tool Execution Loop\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the weather in Berani Sindh?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "  tool_result = get_weather.invoke(tool_call)\n",
    "  messages.append(tool_result)\n",
    "  \n",
    "\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.text)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c120bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is the weather in Berani Sindh?'},\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4swykkg40', 'function': {'arguments': '{\"location\":\"Berani Sindh\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 224, 'total_tokens': 241, 'completion_time': 0.060183006, 'completion_tokens_details': None, 'prompt_time': 0.01293081, 'prompt_tokens_details': None, 'queue_time': 0.008417154, 'total_time': 0.073113816}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb1e4-99c5-7bf3-91fe-cae41c3e0e99-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Berani Sindh'}, 'id': '4swykkg40', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 224, 'output_tokens': 17, 'total_tokens': 241}),\n",
       " ToolMessage(content='The weather in Berani Sindh is sunny', name='get_weather', tool_call_id='4swykkg40')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bac1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Calls: [{'name': 'get_weather', 'args': {'location': 'Berlin'}, 'id': '9ac2a610-f189-48dd-ace6-c3584ee4eb6a', 'type': 'tool_call'}]\n",
      "\n",
      "Tool Name: get_weather\n",
      "Arguments: {'location': 'Berlin'}\n",
      "Tool Call ID: 9ac2a610-f189-48dd-ace6-c3584ee4eb6a\n",
      "\n",
      "Tool Result: The weather in Berlin is sunny\n"
     ]
    }
   ],
   "source": [
    "# Tool calls ko dekhna\n",
    "print(\"Tool Calls:\", response.tool_calls)\n",
    "\n",
    "# Tool call details\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "    print(f\"\\nTool Name: {tool_call['name']}\")\n",
    "    print(f\"Arguments: {tool_call['args']}\")\n",
    "    print(f\"Tool Call ID: {tool_call['id']}\")\n",
    "    \n",
    "    # Actual tool ko execute karna\n",
    "    location = tool_call['args']['location']\n",
    "    result = get_weather.invoke({\"location\": location})\n",
    "    print(f\"\\nTool Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe79945",
   "metadata": {},
   "source": [
    "### Multiple Tools Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9117e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: content='' additional_kwargs={'function_call': {'name': 'get_humidity', 'arguments': '{\"location\": \"Berlin\"}'}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-preview-09-2025', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019bb1ca-a63e-75a0-aae1-59e18a114aeb-0' tool_calls=[{'name': 'get_temperature', 'args': {'location': 'Berlin'}, 'id': 'ef7e26b2-0547-415c-8cde-477b37cda5dd', 'type': 'tool_call'}, {'name': 'get_humidity', 'args': {'location': 'Berlin'}, 'id': 'f9a82d37-43cd-4dd6-97ca-5e17ab473fe0', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 177, 'output_tokens': 38, 'total_tokens': 215, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "Tool Calls: [{'name': 'get_temperature', 'args': {'location': 'Berlin'}, 'id': 'ef7e26b2-0547-415c-8cde-477b37cda5dd', 'type': 'tool_call'}, {'name': 'get_humidity', 'args': {'location': 'Berlin'}, 'id': 'f9a82d37-43cd-4dd6-97ca-5e17ab473fe0', 'type': 'tool_call'}]\n",
      "\n",
      "Tool Name: get_temperature\n",
      "Arguments: {'location': 'Berlin'}\n",
      "Tool Call ID: ef7e26b2-0547-415c-8cde-477b37cda5dd\n",
      "\n",
      "Tool Result: The humidity in Berlin is 65%\n"
     ]
    }
   ],
   "source": [
    "# Multiple tools define karna\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_temperature(location: str) -> str:\n",
    "    \"\"\"Get the temperature in a given location in Celsius\"\"\"\n",
    "    # Dummy data - real mein API call hogi\n",
    "    temps = {\"Berlin\": \"15\", \"Paris\": \"18\", \"London\": \"12\", \"Tokyo\": \"20\"}\n",
    "    return f\"The temperature in {location} is {temps.get(location, '25')}Â°C\"\n",
    "\n",
    "@tool\n",
    "def get_humidity(location: str) -> str:\n",
    "    \"\"\"Get the humidity level in a given location\"\"\"\n",
    "    return f\"The humidity in {location} is 65%\"\n",
    "\n",
    "@tool  \n",
    "def calculate_sum(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Sabhi tools ko bind karna\n",
    "model_with_multiple_tools = model.bind_tools([get_weather, get_temperature, get_humidity, calculate_sum])\n",
    "\n",
    "# Test karna\n",
    "response = model_with_multiple_tools.invoke(\"What is the temperature and humidity in Berlin?\")\n",
    "print(\"Response:\", response)\n",
    "print(\"\\nTool Calls:\", response.tool_calls)\n",
    "\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "    print(f\"\\nTool Name: {tool_call['name']}\")\n",
    "    print(f\"Arguments: {tool_call['args']}\")\n",
    "    print(f\"Tool Call ID: {tool_call['id']}\")\n",
    "    \n",
    "    # Actual tool ko execute karna\n",
    "    location = tool_call['args']['location']\n",
    "    result = get_humidity.invoke({\"location\": location})\n",
    "    print(f\"\\nTool Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed705bef",
   "metadata": {},
   "source": [
    "### Complete Tool Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e76365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Example 1: Weather Query\n",
      "==================================================\n",
      "\n",
      "ðŸ”§ Executing Tool: get_weather\n",
      "ðŸ“ Arguments: {'location': 'Berlin'}\n",
      "âœ… Result: The weather in Berlin is sunny\n",
      "\n",
      "==================================================\n",
      "Example 2: Multiple Tools\n",
      "==================================================\n",
      "\n",
      "ðŸ”§ Executing Tool: get_temperature\n",
      "ðŸ“ Arguments: {'location': 'Paris'}\n",
      "âœ… Result: The temperature in Paris is 18Â°C\n",
      "\n",
      "ðŸ”§ Executing Tool: calculate_sum\n",
      "ðŸ“ Arguments: {'b': 37, 'a': 25}\n",
      "âœ… Result: 62\n"
     ]
    }
   ],
   "source": [
    "# Tool execution helper function\n",
    "def execute_tool_calls(response, tools_dict):\n",
    "    \"\"\"\n",
    "    Tool calls ko execute karta hai aur results return karta hai\n",
    "    \"\"\"\n",
    "    if not response.tool_calls:\n",
    "        return response.content\n",
    "    \n",
    "    results = []\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        print(f\"\\nðŸ”§ Executing Tool: {tool_name}\")\n",
    "        print(f\"ðŸ“ Arguments: {tool_args}\")\n",
    "        \n",
    "        # Tool ko execute karna\n",
    "        if tool_name in tools_dict:\n",
    "            result = tools_dict[tool_name].invoke(tool_args)\n",
    "            print(f\"âœ… Result: {result}\")\n",
    "            results.append({\n",
    "                'tool': tool_name,\n",
    "                'args': tool_args,\n",
    "                'result': result\n",
    "            })\n",
    "        else:\n",
    "            print(f\"âŒ Tool not found: {tool_name}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Tools dictionary banana\n",
    "tools_dict = {\n",
    "    'get_weather': get_weather,\n",
    "    'get_temperature': get_temperature,\n",
    "    'get_humidity': get_humidity,\n",
    "    'calculate_sum': calculate_sum\n",
    "}\n",
    "\n",
    "# Example 1: Weather query\n",
    "print(\"=\"*50)\n",
    "print(\"Example 1: Weather Query\")\n",
    "print(\"=\"*50)\n",
    "response1 = model_with_multiple_tools.invoke(\"What's the weather in Berlin?\")\n",
    "results1 = execute_tool_calls(response1, tools_dict)\n",
    "\n",
    "# Example 2: Multiple tools\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Example 2: Multiple Tools\")\n",
    "print(\"=\"*50)\n",
    "response2 = model_with_multiple_tools.invoke(\"What is the temperature in Paris and calculate 25 + 37\")\n",
    "results2 = execute_tool_calls(response2, tools_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d90bf",
   "metadata": {},
   "source": [
    "### Key Concepts Summary\n",
    "\n",
    "**Tools kya hain?**\n",
    "- Functions jo model call kar sakta hai\n",
    "- External data fetch karne ke liye (APIs, databases, etc.)\n",
    "- Calculations perform karne ke liye\n",
    "- Real-world actions execute karne ke liye\n",
    "\n",
    "**Tool Definition:**\n",
    "```python\n",
    "@tool\n",
    "def function_name(param: type) -> return_type:\n",
    "    \"\"\"Description for the model\"\"\"\n",
    "    return result\n",
    "```\n",
    "\n",
    "**Important Points:**\n",
    "1. **Docstring zaruri hai** - Model isko padhkar decide karta hai kab tool use karna hai\n",
    "2. **Type hints** - Parameters aur return type clear hone chahiye\n",
    "3. **bind_tools()** - Model ko tools attach karta hai\n",
    "4. **tool_calls** - Model ki request for tool execution\n",
    "5. **invoke()** - Actual tool execution\n",
    "\n",
    "**Flow:**\n",
    "1. User query â†’ Model\n",
    "2. Model decides tool chahiye\n",
    "3. Model returns tool_calls (not actual result)\n",
    "4. Hum manually tool execute karte hain\n",
    "5. Result ko model ko wapas bhej sakte hain for final response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
