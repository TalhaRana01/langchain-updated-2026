{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0092bd3b",
   "metadata": {},
   "source": [
    "## Langchain Version V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd56ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838d654",
   "metadata": {},
   "source": [
    "### Generative AI Application Using OpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "response = model.invoke(\"Write me an essay about the benefits of using generative AI\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caaf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5\")\n",
    "\n",
    "response = model.invoke(\"Hello, how are you?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d45ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b933700",
   "metadata": {},
   "source": [
    "### Generative AI Application with Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5eec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Note: Google Gemini model - agar quota issue ho toh OpenAI ya Groq use karein\n",
    "# model = init_chat_model(\"gemini-2.0-flash-exp\", model_provider=\"google_genai\")\n",
    "\n",
    "# Alternative: OpenAI model (Cell 4 mein already working hai)\n",
    "model = init_chat_model(model=\"google_genai:gemini-flash-latest\")\n",
    "\n",
    "response = model.invoke(\"write me a poem about the benefits of using generative AI\")\n",
    "\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6756f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"google_genai:gemini-2.5-flash-lite\")\n",
    "\n",
    "try:\n",
    "  response = model.invoke(\"write me a poem about the benefits of using generative AI\")\n",
    "  response\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655602a",
   "metadata": {},
   "source": [
    "### GROQ Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82618c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model = init_chat_model(model=\"llama-3.1-8b-instant\", model_provider=\"groq\")\n",
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "# model\n",
    "\n",
    "response = model.invoke(\"write me a poem about the benefits of using generative AI\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "\n",
    "response = model.invoke(\"What is the mindest behind the generative AI?\")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"Write me a 500 word essay on the benefits of using generative AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828056f6",
   "metadata": {},
   "source": [
    "## Streaming output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ebe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in  model.stream(\"Write me a 500 word essay on the benefits of using generative AI\"):\n",
    "  # print(chunk)\n",
    "  print(chunk.text, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e00194",
   "metadata": {},
   "source": [
    "## Batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposnse = model.batch(\n",
    "  [\n",
    "    \"Why do parrots have colorful feathers?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What is quantum computing?\",\n",
    "  ],\n",
    "  config={\n",
    "      \"max_concurrency\": 5,  #Limit the number of concurrent requests,\n",
    "    },\n",
    "  \n",
    ")\n",
    "\n",
    "# for chunk in resposnse:\n",
    "#   print(chunk.text, end=\"\", flush=True)\n",
    "\n",
    "response\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
